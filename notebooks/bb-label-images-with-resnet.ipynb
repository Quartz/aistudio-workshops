{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label images using ResNet and fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Given a folder full of images, we want a list of descriptions of each image.\n",
    "\n",
    "### Training models vs. a pre-trained model\n",
    "\n",
    "One way to solve this problem would be to teach, or _train_ a _model_ – really a complex mathematical formula – to match images to labels. For good results, we'd need to use millions of images. It's doable ... but there's another option.\n",
    "\n",
    "That is, use a _pre-trained model_ – one already trained by some other, kind people, who built it using millions of images and then shared it on the internet for others to use. That's what we'll do.\n",
    "\n",
    "\n",
    "### ResNet\n",
    "\n",
    "ResNet[link to paper] is a pre-trained model that was trained on the images and labels of 1.2 million pictures in a database called ImageNet[link].\n",
    "\n",
    "It is a _neural network_ that has \"learned\" how to \"look\" at images and make a guess from 1,000 possible labels.\n",
    "\n",
    "Note that ResNet does not _contain_ 1.2 million images! It contains the complex mathematical formula – the neural network and all of its structure and values – that were fine-tuned by processing those images. We can then use that model to classify (label) images that weren't in the original data set.\n",
    "\n",
    "### fast.ai\n",
    "\n",
    "[Fast.ai](https://fast.ai) is the software we'll use to take the complex mathematical formula described by the ResNet model and apply them to a new image. \n",
    "\n",
    "## The Plan\n",
    "\n",
    "Our steps will be:\n",
    "\n",
    "1. Load some test images\n",
    "1. Prepare the list of 1,000 possible labels (aka classes)\n",
    "1. Load the ResNet model\n",
    "1. Predict the class of an image\n",
    "1. Predict the class of several images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "The code in this notebook is derived from, and includes original code from [this notebook](https://github.com/piegu/fastai-projects/blob/master/pretrained-imagenet-classifier-fastai-v1.ipynb) originally posted by [Pierre Guillou](https://www.linkedin.com/in/pierreguillou). Here are the credits Pierre included in his original post.\n",
    "\n",
    "- Author: [Pierre Guillou](https://www.linkedin.com/in/pierreguillou)\n",
    "- Date: January 2019 (update to fastai 1.0.43 in February 2019)\n",
    "- Source: https://discuss.pytorch.org/t/pretrained-resnet-constant-output/2760\n",
    "- Post in medium: https://medium.com/@pierre_guillou/deep-learning-web-app-by-fastai-v1-3ab4c20b7cac\n",
    "- Ref: [Fastai v1](https://docs.fast.ai/index.html) (Deep Learning library on PyTorch)\n",
    "\n",
    "The code was updated and modified for this notebook by John Keefe at [Quartz](https://qz.com) in October 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For those using Google Colaboratory ...\n",
    "\n",
    "Be aware that Google Colab instances are ephemeral -- they vanish *Poof* when you close them, or after a period of sitting idle (currently 90 minutes), or if you use one for more than 12 hours.\n",
    "\n",
    "Note that we don't need the GPU runtime for this notebook. (That's because we're not _training_ a model, we're just using an existing model as-is.)\n",
    "\n",
    "So first, run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ALL GOOGLE COLAB USERS RUN THIS CELL\n",
    "\n",
    "## This runs a script that installs fast.ai\n",
    "!curl -s https://course.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For those _not_ using Google Colaboratory ...\n",
    "\n",
    "This section is just for people who decide to use one of the notebooks on a system other than Google Colaboartory. \n",
    "\n",
    "Those people should run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NON-COLABORATORY USERS SHOULD RUN THIS CELL\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everybody do this ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyone needs to run the next cell, which initializes the Python libraries we'll use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## AND *EVERYBODY* SHOULD RUN THIS CELL\n",
    "from fastai.vision import *\n",
    "from fastai.widgets import *\n",
    "from IPython.display import Image as Show\n",
    "from IPython.display import display\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import fastai\n",
    "print(f'fastai: {fastai.__version__}')\n",
    "print(f'cuda: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to download some data for this notebook:\n",
    "\n",
    "- A folder containing some **pictures**. These are just pictures I took.\n",
    "\n",
    "- A **json file** containing an ordered list of 1,000 ImageNet labels. We need these because the machine learning model will predict a *number* for the class, such as `3`. We need to turn that `3` into the label for 3, which is `tiger-shark`. This file originally came from here: https://discuss.pytorch.org/t/imagenet-classes/4923/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to download the data we'll use for this exercise\n",
    "!wget -N https://qz-aistudio-public.s3.amazonaws.com/workshops/labelling_images_data.zip --quiet\n",
    "!unzip -q labelling_images_data.zip\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the data on the computer we're using by using the `ls` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%ls data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at an image\n",
    "Show(data_path + 'images/IMG_8027.JPG', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load in and look at that json file of image classifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in the json file\n",
    "json_file = json.load(open(data_path+'imagenet_class_index.json'))\n",
    "\n",
    "classes = [json_file[str(k)][1] for k in range(len(json_file))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the `ResNet50` version of the various ResNet models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get weights of the model and add nn.LogSoftmax(dim=1) to the end\n",
    "model_name = 'resnet50'\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = nn.Sequential(model, nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformation to apply to image before prediction (center crop)\n",
    "# tfms = get_transforms() is possible too\n",
    "tfms = [ [], [crop_pad()] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get an empty databunch with the ImageNet classes\n",
    "# WARNING single_from_classes is deprecated (https://docs.fast.ai/vision.data.html#ImageDataBunch.single_from_classes)\n",
    "data = ImageDataBunch.single_from_classes(data_path, classes, ds_tfms=tfms, size=224).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the learner of the model\n",
    "learn = Learner(data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction for one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grab an image\n",
    "img = open_image(data_path + 'images/IMG_8027.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class, pred_idx, prediction_list = learn.predict(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is its confidence\n",
    "print(round(float(prediction_list[pred_idx] ),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction for all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the list of files\n",
    "image_files = os.listdir(data_path + 'images')\n",
    "print(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop through the list of files\n",
    "for file in image_files:\n",
    "    \n",
    "    img = open_image(data_path + 'images/' + file)\n",
    "    \n",
    "    pred_class, pred_idx, prediction_list = learn.predict(img)\n",
    "    confidence = str(round(float(prediction_list[pred_idx]),2))\n",
    "    \n",
    "    # print the file name and the category guess\n",
    "    print(file, pred_class, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### How did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop through the list of files\n",
    "for file in image_files:\n",
    "    \n",
    "    image_filename = data_path + 'images/' + file\n",
    "    \n",
    "    img = open_image(image_filename)\n",
    "    \n",
    "    pred_class, pred_idx, prediction_list = learn.predict(img)\n",
    "    confidence = str(round(float(prediction_list[pred_idx]),2))\n",
    "\n",
    "    print(f'\\n{str(pred_class)} - confidence: {confidence} - {file}')\n",
    "    display(Show(filename=image_filename, retina=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
